{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae83b83",
   "metadata": {},
   "source": [
    "# * TF 경고 끄기 *\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4d7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7206a",
   "metadata": {},
   "source": [
    "# 데이터셋\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46830b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def train_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32) / 255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32) / 255\n",
    "    inp, targ = augmentation(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def val_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32) / 255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32) / 255\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def augmentation(inp, targ):\n",
    "    inp, targ = random_rot(inp, targ)\n",
    "    inp, targ = random_flip(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def random_rot(inp, targ):\n",
    "    k = np.random.randint(4)\n",
    "    inp = np.rot90(inp, k)\n",
    "    targ = np.rot90(targ, k)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def random_flip(inp, targ):\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.fliplr(inp)\n",
    "        targ = np.fliplr(targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def read_dataset_list(path):\n",
    "    train_csv = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "    test_csv = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    train_all_files = os.path.join(path, 'train_input_img') + os.path.sep + train_csv['input_img']\n",
    "    label_all_files = os.path.join(path, 'train_label_img') + os.path.sep + train_csv['label_img']\n",
    "    \n",
    "    test_all_files = os.path.join(path, 'test_input_img') + os.path.sep + test_csv['input_img']\n",
    "    submission_all_files = os.path.join(path, 'test_input_img') + os.path.sep + test_csv['submission_name']\n",
    "    \n",
    "    train_files = train_all_files[60:].to_numpy()\n",
    "    label_files = label_all_files[60:].to_numpy()\n",
    "    val_train_files = train_all_files[:60].to_numpy()\n",
    "    val_label_files = label_all_files[:60].to_numpy()\n",
    "    return train_files, label_files, val_train_files, val_label_files, test_all_files, submission_all_files\n",
    "\n",
    "\n",
    "def load_preprocessed_dataset(path, batch_size, image_size=256):\n",
    "    # 전처리된 npy 포맷 데이터(shape=[image_size, image_size, 3]) 불러오기\n",
    "    train_input_files = glob(os.path.join(path, f'train_input_img_{image_size}', '*.npy'))\n",
    "    train_label_files = glob(os.path.join(path, f'train_label_img_{image_size}', '*.npy'))\n",
    "    val_input_files = glob(os.path.join(path, f'val_input_img_{image_size}', '*.npy'))\n",
    "    val_label_files = glob(os.path.join(path, f'val_label_img_{image_size}', '*.npy'))\n",
    "    train_input_files, train_label_files = shuffle(train_input_files, train_label_files, random_state=42)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_input_files, train_label_files))\n",
    "    train_dataset = train_dataset.map(lambda i1, i2: tf.numpy_function(train_map_func, [i1, i2], [tf.float32, tf.float32]),\n",
    "                                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_input_files, val_label_files))\n",
    "    val_dataset = val_dataset.map(lambda i1, i2: tf.numpy_function(val_map_func, [i1, i2], [tf.float32, tf.float32]),\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f0519",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d9606",
   "metadata": {},
   "source": [
    "## 모델 정의\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b6b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "\n",
    "\n",
    "def conv2d(filters: int):\n",
    "    return Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                  padding='same', kernel_regularizer=l2(0.), bias_regularizer=l2(0.))\n",
    "\n",
    "\n",
    "def conv2d_transpose(filters: int):\n",
    "    return Conv2DTranspose(filters=filters, kernel_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "\n",
    "def create_unetpp_model(image_size, num_filters=2, dropout_rate=0.25, alpha=0.01):\n",
    "    model_input = Input((image_size, image_size, 3))\n",
    "    x00 = conv2d(filters=int(16 * num_filters))(model_input)\n",
    "    x00 = BatchNormalization()(x00)\n",
    "    x00 = LeakyReLU(alpha)(x00)\n",
    "    x00 = Dropout(dropout_rate)(x00)\n",
    "    x00 = conv2d(filters=int(16 * num_filters))(x00)\n",
    "    x00 = BatchNormalization()(x00)\n",
    "    x00 = LeakyReLU(alpha)(x00)\n",
    "    x00 = Dropout(dropout_rate)(x00)\n",
    "    p0 = MaxPooling2D(pool_size=(2, 2))(x00)\n",
    "\n",
    "    x10 = conv2d(filters=int(32 * num_filters))(p0)\n",
    "    x10 = BatchNormalization()(x10)\n",
    "    x10 = LeakyReLU(alpha)(x10)\n",
    "    x10 = Dropout(dropout_rate)(x10)\n",
    "    x10 = conv2d(filters=int(32 * num_filters))(x10)\n",
    "    x10 = BatchNormalization()(x10)\n",
    "    x10 = LeakyReLU(alpha)(x10)\n",
    "    x10 = Dropout(dropout_rate)(x10)\n",
    "    p1 = MaxPooling2D(pool_size=(2, 2))(x10)\n",
    "\n",
    "    x01 = conv2d_transpose(int(16 * num_filters))(x10)\n",
    "    x01 = concatenate([x00, x01])\n",
    "    x01 = conv2d(filters=int(16 * num_filters))(x01)\n",
    "    x01 = BatchNormalization()(x01)\n",
    "    x01 = LeakyReLU(alpha)(x01)\n",
    "    x01 = conv2d(filters=int(16 * num_filters))(x01)\n",
    "    x01 = BatchNormalization()(x01)\n",
    "    x01 = LeakyReLU(alpha)(x01)\n",
    "    x01 = Dropout(dropout_rate)(x01)\n",
    "\n",
    "    x20 = conv2d(filters=int(64 * num_filters))(p1)\n",
    "    x20 = BatchNormalization()(x20)\n",
    "    x20 = LeakyReLU(alpha)(x20)\n",
    "    x20 = Dropout(dropout_rate)(x20)\n",
    "    x20 = conv2d(filters=int(64 * num_filters))(x20)\n",
    "    x20 = BatchNormalization()(x20)\n",
    "    x20 = LeakyReLU(alpha)(x20)\n",
    "    x20 = Dropout(dropout_rate)(x20)\n",
    "    p2 = MaxPooling2D(pool_size=(2, 2))(x20)\n",
    "\n",
    "    x11 = conv2d_transpose(int(16 * num_filters))(x20)\n",
    "    x11 = concatenate([x10, x11])\n",
    "    x11 = conv2d(filters=int(16 * num_filters))(x11)\n",
    "    x11 = BatchNormalization()(x11)\n",
    "    x11 = LeakyReLU(alpha)(x11)\n",
    "    x11 = conv2d(filters=int(16 * num_filters))(x11)\n",
    "    x11 = BatchNormalization()(x11)\n",
    "    x11 = LeakyReLU(alpha)(x11)\n",
    "    x11 = Dropout(dropout_rate)(x11)\n",
    "\n",
    "    x02 = conv2d_transpose(int(16 * num_filters))(x11)\n",
    "    x02 = concatenate([x00, x01, x02])\n",
    "    x02 = conv2d(filters=int(16 * num_filters))(x02)\n",
    "    x02 = BatchNormalization()(x02)\n",
    "    x02 = LeakyReLU(alpha)(x02)\n",
    "    x02 = conv2d(filters=int(16 * num_filters))(x02)\n",
    "    x02 = BatchNormalization()(x02)\n",
    "    x02 = LeakyReLU(alpha)(x02)\n",
    "    x02 = Dropout(dropout_rate)(x02)\n",
    "\n",
    "    x30 = conv2d(filters=int(128 * num_filters))(p2)\n",
    "    x30 = BatchNormalization()(x30)\n",
    "    x30 = LeakyReLU(alpha)(x30)\n",
    "    x30 = Dropout(dropout_rate)(x30)\n",
    "    x30 = conv2d(filters=int(128 * num_filters))(x30)\n",
    "    x30 = BatchNormalization()(x30)\n",
    "    x30 = LeakyReLU(alpha)(x30)\n",
    "    x30 = Dropout(dropout_rate)(x30)\n",
    "    p3 = MaxPooling2D(pool_size=(2, 2))(x30)\n",
    "\n",
    "    x21 = conv2d_transpose(int(16 * num_filters))(x30)\n",
    "    x21 = concatenate([x20, x21])\n",
    "    x21 = conv2d(filters=int(16 * num_filters))(x21)\n",
    "    x21 = BatchNormalization()(x21)\n",
    "    x21 = LeakyReLU(alpha)(x21)\n",
    "    x21 = conv2d(filters=int(16 * num_filters))(x21)\n",
    "    x21 = BatchNormalization()(x21)\n",
    "    x21 = LeakyReLU(alpha)(x21)\n",
    "    x21 = Dropout(dropout_rate)(x21)\n",
    "\n",
    "    x12 = conv2d_transpose(int(16 * num_filters))(x21)\n",
    "    x12 = concatenate([x10, x11, x12])\n",
    "    x12 = conv2d(filters=int(16 * num_filters))(x12)\n",
    "    x12 = BatchNormalization()(x12)\n",
    "    x12 = LeakyReLU(alpha)(x12)\n",
    "    x12 = conv2d(filters=int(16 * num_filters))(x12)\n",
    "    x12 = BatchNormalization()(x12)\n",
    "    x12 = LeakyReLU(alpha)(x12)\n",
    "    x12 = Dropout(dropout_rate)(x12)\n",
    "\n",
    "    x03 = conv2d_transpose(int(16 * num_filters))(x12)\n",
    "    x03 = concatenate([x00, x01, x02, x03])\n",
    "    x03 = conv2d(filters=int(16 * num_filters))(x03)\n",
    "    x03 = BatchNormalization()(x03)\n",
    "    x03 = LeakyReLU(alpha)(x03)\n",
    "    x03 = conv2d(filters=int(16 * num_filters))(x03)\n",
    "    x03 = BatchNormalization()(x03)\n",
    "    x03 = LeakyReLU(alpha)(x03)\n",
    "    x03 = Dropout(dropout_rate)(x03)\n",
    "\n",
    "    m = conv2d(filters=int(256 * num_filters))(p3)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = LeakyReLU(alpha)(m)\n",
    "    m = conv2d(filters=int(256 * num_filters))(m)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = LeakyReLU(alpha)(m)\n",
    "    m = Dropout(dropout_rate)(m)\n",
    "\n",
    "    x31 = conv2d_transpose(int(128 * num_filters))(m)\n",
    "    x31 = concatenate([x31, x30])\n",
    "    x31 = conv2d(filters=int(128 * num_filters))(x31)\n",
    "    x31 = BatchNormalization()(x31)\n",
    "    x31 = LeakyReLU(alpha)(x31)\n",
    "    x31 = conv2d(filters=int(128 * num_filters))(x31)\n",
    "    x31 = BatchNormalization()(x31)\n",
    "    x31 = LeakyReLU(alpha)(x31)\n",
    "    x31 = Dropout(dropout_rate)(x31)\n",
    "\n",
    "    x22 = conv2d_transpose(int(64 * num_filters))(x31)\n",
    "    x22 = concatenate([x22, x20, x21])\n",
    "    x22 = conv2d(filters=int(64 * num_filters))(x22)\n",
    "    x22 = BatchNormalization()(x22)\n",
    "    x22 = LeakyReLU(alpha)(x22)\n",
    "    x22 = conv2d(filters=int(64 * num_filters))(x22)\n",
    "    x22 = BatchNormalization()(x22)\n",
    "    x22 = LeakyReLU(alpha)(x22)\n",
    "    x22 = Dropout(dropout_rate)(x22)\n",
    "\n",
    "    x13 = conv2d_transpose(int(32 * num_filters))(x22)\n",
    "    x13 = concatenate([x13, x10, x11, x12])\n",
    "    x13 = conv2d(filters=int(32 * num_filters))(x13)\n",
    "    x13 = BatchNormalization()(x13)\n",
    "    x13 = LeakyReLU(alpha)(x13)\n",
    "    x13 = conv2d(filters=int(32 * num_filters))(x13)\n",
    "    x13 = BatchNormalization()(x13)\n",
    "    x13 = LeakyReLU(alpha)(x13)\n",
    "    x13 = Dropout(dropout_rate)(x13)\n",
    "\n",
    "    x04 = conv2d_transpose(int(16 * num_filters))(x13)\n",
    "    x04 = concatenate([x04, x00, x01, x02, x03], axis=3)\n",
    "    x04 = conv2d(filters=int(16 * num_filters))(x04)\n",
    "    x04 = BatchNormalization()(x04)\n",
    "    x04 = LeakyReLU(alpha)(x04)\n",
    "    x04 = conv2d(filters=int(16 * num_filters))(x04)\n",
    "    x04 = BatchNormalization()(x04)\n",
    "    x04 = LeakyReLU(alpha)(x04)\n",
    "    x04 = Dropout(dropout_rate)(x04)\n",
    "    output = tf.keras.layers.Conv2D(3, (1, 1), padding='same', activation='tanh')(x04)   # For reconstruction\n",
    "    return tf.keras.Model(inputs=[model_input], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a911b88",
   "metadata": {},
   "source": [
    "## 학습 매개변수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3746ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "epoch = 5\n",
    "batch_size = 8\n",
    "\n",
    "dropout_rate = 0\n",
    "alpha = 0.01\n",
    "num_filters = 1\n",
    "\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275aebc",
   "metadata": {},
   "source": [
    "## 학습 데이터셋 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb042f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validate_dataset = load_preprocessed_dataset('.\\\\LG_Data', batch_size, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a493eb",
   "metadata": {},
   "source": [
    "## 모델 생성 (새로 학습)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_unetpp_model(image_size, num_filters=num_filters, dropout_rate=dropout_rate, alpha=alpha)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde7ea5",
   "metadata": {},
   "source": [
    "## 모델 생성 (재학습)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('unetpp_recon_256_epoch_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a5165",
   "metadata": {},
   "source": [
    "## 모델 학습 및 저장\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=epoch, validation_data=validate_dataset, callbacks=[\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'unetpp_recon_256_epoch_{epoch}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45439066",
   "metadata": {},
   "source": [
    "# 모델 추론\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3ca41",
   "metadata": {},
   "source": [
    "## 학습된 모델 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5ad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('unetpp_recon_256_epoch_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c50fd",
   "metadata": {},
   "source": [
    "## 모델 추론 함수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ff1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def predict(img_paths, image_size, stride=32, batch_size=128):\n",
    "    results = []\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img.astype(np.float32) / 255\n",
    "        crop = []\n",
    "        position = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        result_img = np.zeros_like(img)\n",
    "        voting_mask = np.zeros_like(img)\n",
    "        \n",
    "        for top in tqdm(range(0, img.shape[0], stride)):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([image_size, image_size, 3], np.float32)\n",
    "                temp = img[top:top + image_size, left:left + image_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                crop.append(piece)\n",
    "                position.append([top, left])\n",
    "                batch_count += 1\n",
    "                if batch_count == batch_size:\n",
    "                    crop = np.array(crop)\n",
    "                    pred = model(crop) * 255\n",
    "                    crop = []\n",
    "                    batch_count=0\n",
    "                    for num, (t, l) in enumerate(position):\n",
    "                        piece = pred[num]\n",
    "                        h,w,c = result_img[t:t + image_size, l:l + image_size,:].shape\n",
    "                        result_img[t:t + image_size, l:l + image_size,:] += piece[:h, :w]\n",
    "                        voting_mask[t:t + image_size, l:l + image_size, :] += 1\n",
    "                    position = []\n",
    "                    \n",
    "        result_img = result_img / voting_mask\n",
    "        result_img = result_img.astype(np.uint8)\n",
    "        results.append(result_img)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7eef89",
   "metadata": {},
   "source": [
    "## 영상 품질 평가 함수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd45b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rmse_score(true, pred):\n",
    "    score = math.sqrt(np.mean((true-pred) ** 2))\n",
    "    return score\n",
    "\n",
    "def psnr_score(true, pred, pixel_max):\n",
    "    score = 20 * np.log10(pixel_max / rmse_score(true,pred))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f85e28",
   "metadata": {},
   "source": [
    "## 추론 매개변수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86fadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d506a4",
   "metadata": {},
   "source": [
    "## 검증/테스트 데이터셋 목록 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5e42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, label_files, val_train_files, val_label_files, test_all_files, _ = read_dataset_list('.\\\\LG_Raw_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e97b463",
   "metadata": {},
   "source": [
    "## 추론 및 결과보기 (Validate)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35285c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [01:10<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "my_slice = 1, 2\n",
    "\n",
    "input_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in val_train_files[my_slice[0]:my_slice[1]]]\n",
    "label_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in val_label_files[my_slice[0]:my_slice[1]]]\n",
    "predicted_images = predict(val_train_files[my_slice[0]:my_slice[1]], image_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ced821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(input_images[0])\n",
    "plt.title('Input', fontsize=10)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_images[0])\n",
    "plt.title('Label', fontsize=10)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(predicted_images[0])\n",
    "plt.title('Predicted', fontsize=10)\n",
    "\n",
    "print(f'PSNR: {psnr_score(label_images[0], predicted_images[0], 255)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db8c31",
   "metadata": {},
   "source": [
    "## 추론 및 결과보기 (Test)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_slice = 0, 1\n",
    "\n",
    "test_input_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in test_all_files[my_slice[0]:my_slice[1]]]\n",
    "predicted_images = predict(test_all_files[my_slice[0]:my_slice[1]], image_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_input_images[0])\n",
    "plt.title('Input', fontsize=10)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_images[0])\n",
    "plt.title('Predicted', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799fa7c",
   "metadata": {},
   "source": [
    "## Submission 생성\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2648e5",
   "metadata": {},
   "source": [
    "### 결과 제출파일 생성 함수\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_submission(result):\n",
    "    root_path = 'submission'\n",
    "    os.makedirs(root_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(\"submission.zip\", 'w') as submit:\n",
    "        for i, img in tqdm(enumerate(result), total=len(result)):\n",
    "            arcname = f'test_{20000 + i}.png'\n",
    "            absname = os.path.join(root_path, arcname)\n",
    "            cv2.imwrite(absname, img)\n",
    "            submit.write(absname, arcname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df47cdaf",
   "metadata": {},
   "source": [
    "### Test 데이터셋 추론\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071df87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "test_input_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in test_all_files]\n",
    "predicted_images = predict(test_all_files, image_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d477f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(predicted_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
