{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35689a2",
   "metadata": {},
   "source": [
    "# * TF 경고 끄기 *\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28386c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ddcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e5c8e",
   "metadata": {},
   "source": [
    "# 데이터셋\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9159f5f",
   "metadata": {},
   "source": [
    "### 원본 데이터셋 목록 생성\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e040534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_raw_dataset_list(path):\n",
    "    train_csv = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "    test_csv = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    \n",
    "    train_input_all_files = os.path.join(path, 'train_input_img') + os.path.sep + train_csv['input_img']\n",
    "    train_label_all_files = os.path.join(path, 'train_label_img') + os.path.sep + train_csv['label_img']\n",
    "    \n",
    "    test_all_files = os.path.join(path, 'test_input_img') + os.path.sep + test_csv['input_img']\n",
    "    submission_all_files = os.path.join(path, 'test_input_img') + os.path.sep + test_csv['submission_name']\n",
    "    \n",
    "    train_input_files = train_input_all_files[60:].to_numpy()\n",
    "    train_label_files = train_label_all_files[60:].to_numpy()\n",
    "    val_input_files = train_input_all_files[:60].to_numpy()\n",
    "    val_label_files = train_label_all_files[:60].to_numpy()\n",
    "    return train_input_files, train_label_files, val_input_files, val_label_files, test_all_files, submission_all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def7eaa",
   "metadata": {},
   "source": [
    "### 데이터셋 생성기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c1c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def train_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = np.squeeze(inp)\n",
    "    inp = np.stack((inp, ) * 3, axis=-1)\n",
    "    inp = inp.astype(np.float32) / 255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = np.squeeze(targ)\n",
    "    targ = np.stack((targ, ) * 3, axis=-1)\n",
    "    targ = targ.astype(np.float32) / 255\n",
    "    inp, targ = augmentation(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def val_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = np.squeeze(inp)\n",
    "    inp = np.stack((inp, ) * 3, axis=-1)\n",
    "    inp = inp.astype(np.float32) / 255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = np.squeeze(targ)\n",
    "    targ = np.stack((targ, ) * 3, axis=-1)\n",
    "    targ = targ.astype(np.float32) / 255\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def augmentation(inp, targ):\n",
    "    inp, targ = random_rot(inp, targ)\n",
    "    inp, targ = random_flip(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def random_rot(inp, targ):\n",
    "    k = np.random.randint(4)\n",
    "    inp = np.rot90(inp, k)\n",
    "    targ = np.rot90(targ, k)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def random_flip(inp, targ):\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.fliplr(inp)\n",
    "        targ = np.fliplr(targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def create_dataset_generator(path, batch_size, image_size, stride):\n",
    "    # 전처리된 npy 포맷 데이터(shape=[image_size, image_size, 1]) 불러오기\n",
    "    train_input_files = glob(os.path.join(path, f'train_input_stride_{stride}_patch_{image_size}_intensity', '*.npy'))\n",
    "    train_label_files = glob(os.path.join(path, f'train_label_stride_{stride}_patch_{image_size}_intensity', '*.npy'))\n",
    "    val_input_files = glob(os.path.join(path, f'val_input_stride_{stride}_patch_{image_size}_intensity', '*.npy'))\n",
    "    val_label_files = glob(os.path.join(path, f'val_labels_stride_{stride}_patch_{image_size}_intensity', '*.npy'))\n",
    "    train_input_files, train_label_files = shuffle(train_input_files, train_label_files, random_state=42)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_input_files, train_label_files))\n",
    "    train_dataset = train_dataset.map(lambda i1, i2: tf.numpy_function(train_map_func, [i1, i2], [tf.float32, tf.float32]),\n",
    "                                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_input_files, val_label_files))\n",
    "    val_dataset = val_dataset.map(lambda i1, i2: tf.numpy_function(val_map_func, [i1, i2], [tf.float32, tf.float32]),\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9ada3",
   "metadata": {},
   "source": [
    "### 데이터셋 가공\n",
    "---\n",
    "원본 데이터셋을 stride만큼 image_size x image_size 정방형 영상으로 나눕니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd4ba9",
   "metadata": {},
   "source": [
    "#### 데이터셋 가공 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_image_as_intensity_patches(image_path_list, save_name, image_size, stride):\n",
    "    save_path = f'{save_name}_stride_{stride}_patch_{image_size}_intensity'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    num = 0\n",
    "    for path in tqdm(image_path_list):\n",
    "        # 이미지 로딩 후, HSI(HSV)로 변환 그리고 I채널만 추출\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        hsv_channels = cv2.split(hsv_img)\n",
    "        intensity_img = hsv_channels[2]\n",
    "        for top in range(0, intensity_img.shape[0], stride):\n",
    "            for left in range(0, intensity_img.shape[1], stride):\n",
    "                patch = intensity_img[top:top + image_size, left:left + image_size]\n",
    "                piece = np.zeros([image_size, image_size, 1], np.uint8)\n",
    "                piece[:patch.shape[0], :patch.shape[1]] = patch[:, :, np.newaxis]\n",
    "                np.save(os.path.join(save_path, f'{num}.npy'), piece.copy())\n",
    "                num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e24dad",
   "metadata": {},
   "source": [
    "#### 원본 데이터셋 파일 목록 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61823741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_input_files, train_label_files, val_input_files, val_label_files, test_all_files, _ = read_raw_dataset_list(os.path.join('.', 'LG_Raw_Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91096822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input_files)\n",
    "print(train_label_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8b5c7",
   "metadata": {},
   "source": [
    "#### 데이터셋 가공 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61248c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "stride = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d29bc",
   "metadata": {},
   "source": [
    "#### 데이터셋 가공 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19251097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print('Processing train inputs...')\n",
    "make_image_as_intensity_patches(train_input_files, os.path.join('.', 'LG_Intensity_Only_Data', 'train_input'), image_size, stride)\n",
    "print('Processing train labels...')\n",
    "make_image_as_intensity_patches(train_label_files, os.path.join('.', 'LG_Intensity_Only_Data', 'train_label'), image_size, stride)\n",
    "print('Processing validation inputs...')\n",
    "make_image_as_intensity_patches(val_input_files, os.path.join('.', 'LG_Intensity_Only_Data', 'val_input'), image_size, stride)\n",
    "print('Processing validation labels...')\n",
    "make_image_as_intensity_patches(val_label_files, os.path.join('.', 'LG_Intensity_Only_Data', 'val_labels'), image_size, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635e330",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9ab75",
   "metadata": {},
   "source": [
    "## 모델 정의\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25b8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = tf.keras.layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1)(blockInput)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    blockInput = tf.keras.layers.BatchNormalization()(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = tf.keras.layers.Add()([x, blockInput])\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResUNet101V2(image_size, weights='imagenet', dropout_rate=0.1, start_neurons=16):\n",
    "    input_shape=(image_size, image_size, 3)\n",
    "    backbone = tf.keras.applications.ResNet101V2(weights=weights, include_top=False, input_shape=input_shape)\n",
    "    input_layer = backbone.input\n",
    "\n",
    "    conv4 = backbone.layers[122].output\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = tf.keras.layers.Dropout(dropout_rate)(pool4)\n",
    "\n",
    "    convm = tf.keras.layers.Conv2D(start_neurons * 32, (3, 3), activation=None, padding='same')(pool4)\n",
    "    convm = residual_block(convm, start_neurons * 32)\n",
    "    convm = residual_block(convm, start_neurons * 32)\n",
    "    convm = tf.keras.layers.LeakyReLU(alpha=0.1)(convm)\n",
    "\n",
    "    deconv4 = tf.keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding='same')(convm)\n",
    "    uconv4 = tf.keras.layers.concatenate([deconv4, conv4])\n",
    "    uconv4 = tf.keras.layers.Dropout(dropout_rate)(uconv4)\n",
    "\n",
    "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=None, padding='same')(uconv4)\n",
    "    uconv4 = residual_block(uconv4, start_neurons * 16)\n",
    "    uconv4 = residual_block(uconv4, start_neurons * 16)\n",
    "    uconv4 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv4)\n",
    "\n",
    "    deconv3 = tf.keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding='same')(uconv4)\n",
    "    conv3 = backbone.layers[76].output\n",
    "    uconv3 = tf.keras.layers.concatenate([deconv3, conv3])\n",
    "    uconv3 = tf.keras.layers.Dropout(dropout_rate)(uconv3)\n",
    "\n",
    "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=None, padding='same')(uconv3)\n",
    "    uconv3 = residual_block(uconv3, start_neurons * 8)\n",
    "    uconv3 = residual_block(uconv3, start_neurons * 8)\n",
    "    uconv3 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv3)\n",
    "\n",
    "    deconv2 = tf.keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding='same')(uconv3)\n",
    "    conv2 = backbone.layers[30].output\n",
    "    uconv2 = tf.keras.layers.concatenate([deconv2, conv2])\n",
    "\n",
    "    uconv2 = tf.keras.layers.Dropout(0.1)(uconv2)\n",
    "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=None, padding='same')(uconv2)\n",
    "    uconv2 = residual_block(uconv2, start_neurons * 4)\n",
    "    uconv2 = residual_block(uconv2, start_neurons * 4)\n",
    "    uconv2 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv2)\n",
    "\n",
    "    deconv1 = tf.keras.layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding='same')(uconv2)\n",
    "    conv1 = backbone.layers[2].output\n",
    "    uconv1 = tf.keras.layers.concatenate([deconv1, conv1])\n",
    "\n",
    "    uconv1 = tf.keras.layers.Dropout(0.1)(uconv1)\n",
    "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=None, padding='same')(uconv1)\n",
    "    uconv1 = residual_block(uconv1, start_neurons * 2)\n",
    "    uconv1 = residual_block(uconv1, start_neurons * 2)\n",
    "    uconv1 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv1)\n",
    "\n",
    "    uconv0 = tf.keras.layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding='same')(uconv1)\n",
    "    uconv0 = tf.keras.layers.Dropout(0.1)(uconv0)\n",
    "    uconv0 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=None, padding='same')(uconv0)\n",
    "    uconv0 = residual_block(uconv0, start_neurons * 1)\n",
    "    uconv0 = residual_block(uconv0, start_neurons * 1)\n",
    "    uconv0 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv0)\n",
    "\n",
    "    uconv0 = tf.keras.layers.Dropout(dropout_rate / 2)(uconv0)\n",
    "    output_layer = tf.keras.layers.Conv2D(3, (1, 1), padding='same', activation='sigmoid')(uconv0)\n",
    "\n",
    "    model = tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9560b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "\n",
    "\n",
    "def conv2d(filters: int):\n",
    "    return Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                  padding='same', kernel_regularizer=l2(0.), bias_regularizer=l2(0.))\n",
    "\n",
    "\n",
    "def conv2d_transpose(filters: int):\n",
    "    return Conv2DTranspose(filters=filters, kernel_size=(2, 2), strides=(2, 2), padding='same')\n",
    "\n",
    "\n",
    "def create_unetpp_model(image_size, channels=1, num_filters=2, dropout_rate=0, alpha=0.01):\n",
    "    model_input = Input((image_size, image_size, channels))\n",
    "    x00 = conv2d(filters=int(16 * num_filters))(model_input)\n",
    "    x00 = BatchNormalization()(x00)\n",
    "    x00 = LeakyReLU(alpha)(x00)\n",
    "    x00 = Dropout(dropout_rate)(x00)\n",
    "    x00 = conv2d(filters=int(16 * num_filters))(x00)\n",
    "    x00 = BatchNormalization()(x00)\n",
    "    x00 = LeakyReLU(alpha)(x00)\n",
    "    x00 = Dropout(dropout_rate)(x00)\n",
    "    p0 = MaxPooling2D(pool_size=(2, 2))(x00)\n",
    "\n",
    "    x10 = conv2d(filters=int(32 * num_filters))(p0)\n",
    "    x10 = BatchNormalization()(x10)\n",
    "    x10 = LeakyReLU(alpha)(x10)\n",
    "    x10 = Dropout(dropout_rate)(x10)\n",
    "    x10 = conv2d(filters=int(32 * num_filters))(x10)\n",
    "    x10 = BatchNormalization()(x10)\n",
    "    x10 = LeakyReLU(alpha)(x10)\n",
    "    x10 = Dropout(dropout_rate)(x10)\n",
    "    p1 = MaxPooling2D(pool_size=(2, 2))(x10)\n",
    "\n",
    "    x01 = conv2d_transpose(int(16 * num_filters))(x10)\n",
    "    x01 = concatenate([x00, x01])\n",
    "    x01 = conv2d(filters=int(16 * num_filters))(x01)\n",
    "    x01 = BatchNormalization()(x01)\n",
    "    x01 = LeakyReLU(alpha)(x01)\n",
    "    x01 = conv2d(filters=int(16 * num_filters))(x01)\n",
    "    x01 = BatchNormalization()(x01)\n",
    "    x01 = LeakyReLU(alpha)(x01)\n",
    "    x01 = Dropout(dropout_rate)(x01)\n",
    "\n",
    "    x20 = conv2d(filters=int(64 * num_filters))(p1)\n",
    "    x20 = BatchNormalization()(x20)\n",
    "    x20 = LeakyReLU(alpha)(x20)\n",
    "    x20 = Dropout(dropout_rate)(x20)\n",
    "    x20 = conv2d(filters=int(64 * num_filters))(x20)\n",
    "    x20 = BatchNormalization()(x20)\n",
    "    x20 = LeakyReLU(alpha)(x20)\n",
    "    x20 = Dropout(dropout_rate)(x20)\n",
    "    p2 = MaxPooling2D(pool_size=(2, 2))(x20)\n",
    "\n",
    "    x11 = conv2d_transpose(int(16 * num_filters))(x20)\n",
    "    x11 = concatenate([x10, x11])\n",
    "    x11 = conv2d(filters=int(16 * num_filters))(x11)\n",
    "    x11 = BatchNormalization()(x11)\n",
    "    x11 = LeakyReLU(alpha)(x11)\n",
    "    x11 = conv2d(filters=int(16 * num_filters))(x11)\n",
    "    x11 = BatchNormalization()(x11)\n",
    "    x11 = LeakyReLU(alpha)(x11)\n",
    "    x11 = Dropout(dropout_rate)(x11)\n",
    "\n",
    "    x02 = conv2d_transpose(int(16 * num_filters))(x11)\n",
    "    x02 = concatenate([x00, x01, x02])\n",
    "    x02 = conv2d(filters=int(16 * num_filters))(x02)\n",
    "    x02 = BatchNormalization()(x02)\n",
    "    x02 = LeakyReLU(alpha)(x02)\n",
    "    x02 = conv2d(filters=int(16 * num_filters))(x02)\n",
    "    x02 = BatchNormalization()(x02)\n",
    "    x02 = LeakyReLU(alpha)(x02)\n",
    "    x02 = Dropout(dropout_rate)(x02)\n",
    "\n",
    "    x30 = conv2d(filters=int(128 * num_filters))(p2)\n",
    "    x30 = BatchNormalization()(x30)\n",
    "    x30 = LeakyReLU(alpha)(x30)\n",
    "    x30 = Dropout(dropout_rate)(x30)\n",
    "    x30 = conv2d(filters=int(128 * num_filters))(x30)\n",
    "    x30 = BatchNormalization()(x30)\n",
    "    x30 = LeakyReLU(alpha)(x30)\n",
    "    x30 = Dropout(dropout_rate)(x30)\n",
    "    p3 = MaxPooling2D(pool_size=(2, 2))(x30)\n",
    "\n",
    "    x21 = conv2d_transpose(int(16 * num_filters))(x30)\n",
    "    x21 = concatenate([x20, x21])\n",
    "    x21 = conv2d(filters=int(16 * num_filters))(x21)\n",
    "    x21 = BatchNormalization()(x21)\n",
    "    x21 = LeakyReLU(alpha)(x21)\n",
    "    x21 = conv2d(filters=int(16 * num_filters))(x21)\n",
    "    x21 = BatchNormalization()(x21)\n",
    "    x21 = LeakyReLU(alpha)(x21)\n",
    "    x21 = Dropout(dropout_rate)(x21)\n",
    "\n",
    "    x12 = conv2d_transpose(int(16 * num_filters))(x21)\n",
    "    x12 = concatenate([x10, x11, x12])\n",
    "    x12 = conv2d(filters=int(16 * num_filters))(x12)\n",
    "    x12 = BatchNormalization()(x12)\n",
    "    x12 = LeakyReLU(alpha)(x12)\n",
    "    x12 = conv2d(filters=int(16 * num_filters))(x12)\n",
    "    x12 = BatchNormalization()(x12)\n",
    "    x12 = LeakyReLU(alpha)(x12)\n",
    "    x12 = Dropout(dropout_rate)(x12)\n",
    "\n",
    "    x03 = conv2d_transpose(int(16 * num_filters))(x12)\n",
    "    x03 = concatenate([x00, x01, x02, x03])\n",
    "    x03 = conv2d(filters=int(16 * num_filters))(x03)\n",
    "    x03 = BatchNormalization()(x03)\n",
    "    x03 = LeakyReLU(alpha)(x03)\n",
    "    x03 = conv2d(filters=int(16 * num_filters))(x03)\n",
    "    x03 = BatchNormalization()(x03)\n",
    "    x03 = LeakyReLU(alpha)(x03)\n",
    "    x03 = Dropout(dropout_rate)(x03)\n",
    "\n",
    "    m = conv2d(filters=int(256 * num_filters))(p3)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = LeakyReLU(alpha)(m)\n",
    "    m = conv2d(filters=int(256 * num_filters))(m)\n",
    "    m = BatchNormalization()(m)\n",
    "    m = LeakyReLU(alpha)(m)\n",
    "    m = Dropout(dropout_rate)(m)\n",
    "\n",
    "    x31 = conv2d_transpose(int(128 * num_filters))(m)\n",
    "    x31 = concatenate([x31, x30])\n",
    "    x31 = conv2d(filters=int(128 * num_filters))(x31)\n",
    "    x31 = BatchNormalization()(x31)\n",
    "    x31 = LeakyReLU(alpha)(x31)\n",
    "    x31 = conv2d(filters=int(128 * num_filters))(x31)\n",
    "    x31 = BatchNormalization()(x31)\n",
    "    x31 = LeakyReLU(alpha)(x31)\n",
    "    x31 = Dropout(dropout_rate)(x31)\n",
    "\n",
    "    x22 = conv2d_transpose(int(64 * num_filters))(x31)\n",
    "    x22 = concatenate([x22, x20, x21])\n",
    "    x22 = conv2d(filters=int(64 * num_filters))(x22)\n",
    "    x22 = BatchNormalization()(x22)\n",
    "    x22 = LeakyReLU(alpha)(x22)\n",
    "    x22 = conv2d(filters=int(64 * num_filters))(x22)\n",
    "    x22 = BatchNormalization()(x22)\n",
    "    x22 = LeakyReLU(alpha)(x22)\n",
    "    x22 = Dropout(dropout_rate)(x22)\n",
    "\n",
    "    x13 = conv2d_transpose(int(32 * num_filters))(x22)\n",
    "    x13 = concatenate([x13, x10, x11, x12])\n",
    "    x13 = conv2d(filters=int(32 * num_filters))(x13)\n",
    "    x13 = BatchNormalization()(x13)\n",
    "    x13 = LeakyReLU(alpha)(x13)\n",
    "    x13 = conv2d(filters=int(32 * num_filters))(x13)\n",
    "    x13 = BatchNormalization()(x13)\n",
    "    x13 = LeakyReLU(alpha)(x13)\n",
    "    x13 = Dropout(dropout_rate)(x13)\n",
    "\n",
    "    x04 = conv2d_transpose(int(16 * num_filters))(x13)\n",
    "    x04 = concatenate([x04, x00, x01, x02, x03], axis=3)\n",
    "    x04 = conv2d(filters=int(16 * num_filters))(x04)\n",
    "    x04 = BatchNormalization()(x04)\n",
    "    x04 = LeakyReLU(alpha)(x04)\n",
    "    x04 = conv2d(filters=int(16 * num_filters))(x04)\n",
    "    x04 = BatchNormalization()(x04)\n",
    "    x04 = LeakyReLU(alpha)(x04)\n",
    "    x04 = Dropout(dropout_rate)(x04)\n",
    "    output = tf.keras.layers.Conv2D(channels, (1, 1), padding='same', activation='sigmoid')(x04)   # For reconstruction\n",
    "    return tf.keras.Model(inputs=[model_input], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe2b97",
   "metadata": {},
   "source": [
    "## 학습 매개변수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c03b21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "stride = 128\n",
    "epoch = 1\n",
    "batch_size = 8\n",
    "\n",
    "psnr_weight = 1\n",
    "ssim_weight = 1\n",
    "recon_weight = 1\n",
    "\n",
    "learning_rate = 1e-5\n",
    "\n",
    "model_filename = f'ResUNet101V2_psnr_ssim_recon_input_{image_size}_epoch_{epoch}_best.h5'\n",
    "model_filename_last = f'ResUNet101V2_psnr_ssim_recon_input_{image_size}_epoch_{epoch}_last.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fdf0a1",
   "metadata": {},
   "source": [
    "## 학습 데이터셋 생성기 생성\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56673319",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validate_generator = create_dataset_generator('.\\\\LG_Intensity_Only_Data', batch_size, image_size, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93a2e3",
   "metadata": {},
   "source": [
    "## 모델 생성 (새로 학습)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc89ec",
   "metadata": {},
   "source": [
    "#### 사용자 정의 로스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fcf2528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1. - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def psnr_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def recon_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def create_psnr_ssim_recon_combined_loss(psnr_weight, ssim_weight, recon_weight):\n",
    "    def psnr_ssim_recon_combined_loss(y_true, y_pred):\n",
    "        return (psnr_weight * psnr_loss(y_true, y_pred)) + (ssim_weight * ssim_loss(y_true, y_pred)) + (recon_weight * recon_loss(y_true, y_pred))\n",
    "    return psnr_ssim_recon_combined_loss\n",
    "\n",
    "combined_loss = create_psnr_ssim_recon_combined_loss(psnr_weight, ssim_weight, recon_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c6124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_unetpp_model(image_size, num_filters=num_filters, dropout_rate=dropout_rate, alpha=alpha)\n",
    "model = ResUNet101V2(image_size)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss=combined_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86a8125",
   "metadata": {},
   "source": [
    "## 모델 생성 (재학습)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbb102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_filename, custom_objects={combined_loss.__name__: combined_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e79035",
   "metadata": {},
   "source": [
    "## 모델 학습 및 저장\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a440068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3385/19468 [====>.........................] - ETA: 52:59 - loss: 0.7811"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=epoch, validation_data=validate_generator, callbacks=[\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_filename,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_filename_last,\n",
    "        save_freq=512\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47fc99",
   "metadata": {},
   "source": [
    "# 모델 추론\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b6706",
   "metadata": {},
   "source": [
    "## 학습된 모델 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_filename, custom_objects={combined_loss.__name__: combined_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa49126",
   "metadata": {},
   "source": [
    "## 모델 추론 함수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def predict(img_paths, image_size, stride=32, batch_size=128):\n",
    "    results = []\n",
    "    for img_path in img_paths:\n",
    "        ori_img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        hsv_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2HSV)\n",
    "        hsv_channels = cv2.split(hsv_img)\n",
    "        intensity_img = hsv_channels[2]\n",
    "        intensity_img = np.stack((intensity_img, ) * 3, axis=-1)\n",
    "        \n",
    "        img = intensity_img.astype(np.float32) / 255\n",
    "        crop = []\n",
    "        position = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        result_img = np.zeros_like(img)\n",
    "        voting_mask = np.zeros_like(img)\n",
    "        for top in tqdm(range(0, img.shape[0], stride)):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([image_size, image_size, 3], np.float32)\n",
    "                temp = img[top:top + image_size, left:left + image_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                crop.append(piece)\n",
    "                position.append([top, left])\n",
    "                batch_count += 1\n",
    "                if batch_count == batch_size:\n",
    "                    crop = np.array(crop)\n",
    "                    pred = model(crop) * 255\n",
    "                    crop = []\n",
    "                    batch_count=0\n",
    "                    for num, (t, l) in enumerate(position):\n",
    "                        piece = pred[num]\n",
    "                        h, w, c = result_img[t:t + image_size, l:l + image_size,:].shape\n",
    "                        result_img[t:t + image_size, l:l + image_size,:] += piece[:h, :w]\n",
    "                        voting_mask[t:t + image_size, l:l + image_size, :] += 1\n",
    "                    position = []\n",
    "                    \n",
    "        result_img = result_img / voting_mask\n",
    "        result_img = result_img.astype(np.uint8)\n",
    "        \n",
    "        hsv_channels[2] = np.squeeze(cv2.cvtColor(result_img, cv2.COLOR_BGR2GRAY))\n",
    "        merged_hsv_img = cv2.merge(hsv_channels)\n",
    "        merged_img = cv2.cvtColor(merged_hsv_img, cv2.COLOR_HSV2BGR)\n",
    "        results.append((result_img, merged_img))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1741f",
   "metadata": {},
   "source": [
    "## 영상 품질 평가 함수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59863bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rmse_score(true, pred):\n",
    "    score = math.sqrt(np.mean((true - pred) ** 2))\n",
    "    return score\n",
    "\n",
    "def psnr_score(true, pred, pixel_max):\n",
    "    score = 20 * np.log10(pixel_max / rmse_score(true,pred))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29a15e",
   "metadata": {},
   "source": [
    "## 추론 매개변수 선언\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "stride = 128\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021b98d",
   "metadata": {},
   "source": [
    "## 검증/테스트 데이터셋 목록 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa41181",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_files, train_label_files, val_input_files, val_label_files, test_all_files, _ = read_raw_dataset_list(os.path.join('.', 'LG_Raw_Data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae22dc1",
   "metadata": {},
   "source": [
    "## 추론 및 결과보기 (Validate)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_slice = 1, 2\n",
    "\n",
    "input_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in val_input_files[my_slice[0]:my_slice[1]]]\n",
    "label_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in val_label_files[my_slice[0]:my_slice[1]]]\n",
    "predicted_images = predict(val_input_files[my_slice[0]:my_slice[1]], image_size, stride, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(input_images[0])\n",
    "plt.title('Input', fontsize=10)\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(label_images[0])\n",
    "plt.title('Label', fontsize=10)\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(predicted_images[0][0], cmap='gray')\n",
    "plt.title('Predicted (Intensity Only)', fontsize=10)\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(predicted_images[0][1])\n",
    "plt.title('Predicted', fontsize=10)\n",
    "\n",
    "print(f'PSNR: {psnr_score(label_images[0], predicted_images[0][1], 255)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
